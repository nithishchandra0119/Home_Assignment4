# Home_Assignment4
GANGARAPU NITHISH CHANDRA
Okay, here's a slightly expanded brief for each question, suitable for an explanation video:

Q1: NLP Preprocessing Pipeline**

Core Idea: This section introduces the crucial initial steps in preparing text data for NLP tasks. We'll demonstrate how to break down sentences into individual words (tokenization), remove common but less informative words (stop words), and reduce words to their base forms (stemming) using Python's NLTK library.
Practical Demonstration: The Python function will visually show the transformation of the example sentence through each stage, making the concepts concrete. The printed outputs will clearly illustrate the effect of tokenization, stop word removal, and stemming.


Q2: Named Entity Recognition with SpaCy

 Core Idea: This segment focuses on identifying and categorizing important entities within text, such as people, organizations, and dates. We'll utilize the spaCy library, a powerful tool for advanced NLP, to automatically extract these entities from a given sentence.
 Practical Demonstration: The Python code using spaCy will process the example sentence, and the output will clearly show each identified entity along with its type (label) and its position within the original sentence.

Q3: Scaled Dot-Product Attention

Core Idea: This section delves into a fundamental building block of modern neural networks, particularly transformers. We'll implement the scaled dot-product attention mechanism using NumPy, breaking down the calculation step-by-step: calculating similarity between queries and keys, scaling these scores, applying softmax to get attention weights, and finally using these weights to focus on relevant values.
Practical Demonstration: The Python code will take sample query, key, and value matrices as input and output the resulting attention weights and the final output matrix, illustrating the flow of information.


Q4: Sentiment Analysis using HuggingFace Transformers

Core Idea: This part showcases the power of pre-trained transformer models for a common NLP task: sentiment analysis. We'll use the HuggingFace Transformers library, a user-friendly interface to state-of-the-art models, to load a pre-built sentiment analysis pipeline.
Practical Demonstration:The Python code will load the pipeline and then analyze a sample sentence with mixed sentiment, printing the predicted sentiment label (positive or negative) and the confidence score associated with that prediction.
